{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17b5f788",
   "metadata": {},
   "source": [
    "# NZ → China Exports Pipeline (2021–2024)\n",
    "\n",
    "This notebook is an `.ipynb` version of your script. It:\n",
    "- Loads Stats NZ OMT HS10 CSVs from the `data/` folder\n",
    "- Filters China exports and maps HS chapters to sectors (Dairy, Meat, Fruit, Forestry)\n",
    "- Produces aggregated long + wide datasets\n",
    "- Runs a small EDA section (trend + correlation plots)\n",
    "- Trains/compares ARIMA, Prophet (optional), Random Forest, XGBoost (optional), LSTM (optional)\n",
    "\n",
    "**Before running:**\n",
    "1. Put your raw CSV files in a folder named `data` in the same directory as this notebook.\n",
    "2. Run all cells from top to bottom.\n",
    "\n",
    "Outputs:\n",
    "- `omt_hs10_china_aggregated.csv`\n",
    "- `omt_hs10_china_aggregated_wide.csv`\n",
    "- `out_forecasts/` (plots, forecast CSVs, SHAP summaries, metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ecab9a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_pipeline.py\n",
    "# NZ → China Exports — End-to-End Pipeline with EDA & Forecasts (2021–2024)\n",
    "\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff482607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29b8acfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "IN_DIR = Path(\"data\")\n",
    "OUT_FILE_LONG = Path(\"omt_hs10_china_aggregated.csv\")\n",
    "OUT_FILE_WIDE = Path(\"omt_hs10_china_aggregated_wide.csv\")\n",
    "OUT_DIR = Path(\"out_forecasts\")\n",
    "OUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Prefer 'total_export_FOB' if present (some Stats NZ extractions include this)\n",
    "PREFER_TOTAL_EXPORTS = False\n",
    "\n",
    "# HS chapter → sector map (your assignment’s 4 sectors)\n",
    "SECTOR_MAP = {\"02\": \"Meat\", \"04\": \"Dairy\", \"08\": \"Fruit\", \"44\": \"Forestry\"}\n",
    "KEEP_SECTORS = [\"Dairy\", \"Meat\", \"Fruit\", \"Forestry\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da14ceac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Optional model deps (fail-soft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c59098e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "HAVE_PROPHET = True\n",
    "try:\n",
    "    from prophet import Prophet\n",
    "except Exception:\n",
    "    HAVE_PROPHET = False\n",
    "\n",
    "HAVE_XGB = True\n",
    "try:\n",
    "    from xgboost import XGBRegressor\n",
    "except Exception:\n",
    "    HAVE_XGB = False\n",
    "\n",
    "HAVE_TF = True\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import LSTM, Dense\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "except Exception:\n",
    "    HAVE_TF = False\n",
    "\n",
    "HAVE_SHAP = True\n",
    "try:\n",
    "    import shap\n",
    "except Exception:\n",
    "    HAVE_SHAP = False\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from statsmodels.tsa.arima.model import ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34a857ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b836103f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1838844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "def detect_col(df, candidates, required_name):\n",
    "    lower_map = {c.lower(): c for c in df.columns}\n",
    "    for cand in candidates:\n",
    "        if cand.lower() in lower_map:\n",
    "            return lower_map[cand.lower()]\n",
    "    raise KeyError(\n",
    "        f\"Missing required column for '{required_name}'. \"\n",
    "        f\"Tried {candidates}. Available: {list(df.columns)}\"\n",
    "    )\n",
    "\n",
    "def pick_exports_column(df: pd.DataFrame, prefer_total: bool) -> str:\n",
    "    lower_map = {c.lower(): c for c in df.columns}\n",
    "    ordered = []\n",
    "    if prefer_total:\n",
    "        ordered += [\"total_export_fob\"]\n",
    "    ordered += [\"export_fob\", \"exports ($nzd fob)\", \"exports\", \"value\", \"total_export_fob\"]\n",
    "    for cand in ordered:\n",
    "        if cand in lower_map:\n",
    "            return lower_map[cand]\n",
    "    raise KeyError(\n",
    "        \"No exports value column found. \"\n",
    "        \"Looked for Export_FOB / total_export_FOB / 'Exports ($NZD FOB)' / Exports / Value.\"\n",
    "    )\n",
    "\n",
    "def to_chapter(x):\n",
    "    if pd.isna(x):\n",
    "        return np.nan\n",
    "    s = \"\".join(ch for ch in str(x) if ch.isdigit())\n",
    "    return s[:2].zfill(2) if s else np.nan\n",
    "\n",
    "def infer_sector_from_desc(desc: str):\n",
    "    if not isinstance(desc, str):\n",
    "        return None\n",
    "    d = desc.lower()\n",
    "    if any(k in d for k in [\"milk\",\"dairy\",\"butter\",\"cheese\",\"whey\"]): return \"Dairy\"\n",
    "    if any(k in d for k in [\"meat\",\"beef\",\"bovine\",\"lamb\",\"mutton\",\"pork\",\"swine\",\"offal\"]): return \"Meat\"\n",
    "    if any(k in d for k in [\"fruit\",\"apple\",\"kiwifruit\",\"pear\",\"cherry\"]): return \"Fruit\"\n",
    "    if any(k in d for k in [\"wood\",\"logs\",\"timber\",\"lumber\",\"pulp\",\"sawn\"]): return \"Forestry\"\n",
    "    return None\n",
    "\n",
    "def month_floor_to_str(s: pd.Series) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Robustly parse month field and return 'Mon-YYYY' strings.\n",
    "    Filters out pre-2000 accidents (just to avoid Excel-serial garbage).\n",
    "    \"\"\"\n",
    "    s = pd.Series(s)\n",
    "    s_str = s.astype(str).str.strip()\n",
    "    dt = pd.Series(pd.NaT, index=s.index, dtype=\"datetime64[ns]\")\n",
    "\n",
    "    # 1) 'Mon-YYYY'\n",
    "    mask = s_str.str.fullmatch(r\"[A-Za-z]{3}-\\d{4}\")\n",
    "    if mask.any():\n",
    "        dt.loc[mask] = pd.to_datetime(s_str[mask], format=\"%b-%Y\", errors=\"coerce\")\n",
    "\n",
    "    # 2) ISO: YYYY-MM-DD\n",
    "    rem = dt.isna()\n",
    "    mask = rem & s_str.str.fullmatch(r\"\\d{4}-\\d{2}-\\d{2}\")\n",
    "    if mask.any():\n",
    "        dt.loc[mask] = pd.to_datetime(s_str[mask], format=\"%Y-%m-%d\", errors=\"coerce\")\n",
    "\n",
    "    # 3) DMY: DD/MM/YYYY\n",
    "    rem = dt.isna()\n",
    "    mask = rem & s_str.str.fullmatch(r\"\\d{2}/\\d{2}/\\d{4}\")\n",
    "    if mask.any():\n",
    "        dt.loc[mask] = pd.to_datetime(s_str[mask], format=\"%d/%m/%Y\", errors=\"coerce\")\n",
    "\n",
    "    # 4) 'YYYY-MM' -> append -01\n",
    "    rem = dt.isna()\n",
    "    mask = rem & s_str.str.fullmatch(r\"\\d{4}-\\d{2}\")\n",
    "    if mask.any():\n",
    "        dt.loc[mask] = pd.to_datetime(s_str[mask] + \"-01\", format=\"%Y-%m-%d\", errors=\"coerce\")\n",
    "\n",
    "    # 5) 'YYYYMM'\n",
    "    rem = dt.isna()\n",
    "    mask = rem & s_str.str.fullmatch(r\"\\d{6}\")\n",
    "    if mask.any():\n",
    "        dt.loc[mask] = pd.to_datetime(s_str[mask], format=\"%Y%m\", errors=\"coerce\")\n",
    "\n",
    "    # 6) Excel serials (rough guard band)\n",
    "    rem = dt.isna()\n",
    "    if rem.any():\n",
    "        nums = pd.to_numeric(s_str[rem], errors=\"coerce\")\n",
    "        excel_mask = (nums > 20000) & (nums < 60000)\n",
    "        if excel_mask.any():\n",
    "            idx = nums[excel_mask].index\n",
    "            dt.loc[idx] = pd.to_datetime(nums[excel_mask], unit=\"d\", origin=\"1899-12-30\", errors=\"coerce\")\n",
    "\n",
    "    # Floor to month and drop silly early dates\n",
    "    dt = dt.dt.to_period(\"M\").dt.to_timestamp()\n",
    "    bad = dt.notna() & (dt.dt.year < 2000)\n",
    "    if bad.any():\n",
    "        dt.loc[bad] = pd.NaT\n",
    "\n",
    "    return dt.dt.strftime(\"%b-%Y\")\n",
    "\n",
    "def load_and_stack(in_dir: Path) -> pd.DataFrame:\n",
    "    csvs = sorted(in_dir.glob(\"*.csv\"))\n",
    "    if not csvs:\n",
    "        raise FileNotFoundError(f\"No CSV files found in: {in_dir.resolve()}\")\n",
    "    frames = []\n",
    "    for p in csvs:\n",
    "        try:\n",
    "            df = pd.read_csv(p)\n",
    "        except UnicodeDecodeError:\n",
    "            df = pd.read_csv(p, encoding=\"latin-1\")\n",
    "        frames.append(df)\n",
    "    out = pd.concat(frames, ignore_index=True)\n",
    "    print(\"[INFO] Loaded rows:\", len(out), \"Columns:\", list(out.columns))\n",
    "    return out\n",
    "\n",
    "def normalize_and_filter(df: pd.DataFrame, prefer_total: bool) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    China-only rows, HS→Sector mapping, numeric exports, month clamp (2021–2024).\n",
    "    \"\"\"\n",
    "    # Column detection\n",
    "    month_col   = detect_col(df, [\"Month\",\"month\",\"Date\",\"Period\"], \"Month\")\n",
    "    hs_col      = detect_col(df, [\"Harmonised System Code\",\"Harmonized System Code\",\"HS Code\",\"HS code\",\"HS_Code\",\"HSCode\",\"hs\"], \"HS Code\")\n",
    "    partner_col = detect_col(df, [\"Partner\",\"Partner Country\",\"Country\",\"Destination\",\"country\"], \"Partner\")\n",
    "    exports_col = pick_exports_column(df, prefer_total)\n",
    "\n",
    "    # Optional HS description\n",
    "    hs_desc_col = None\n",
    "    for cand in [\"hs_desc\",\"HS_Desc\",\"HS Description\",\"hs description\",\"Description\"]:\n",
    "        if cand in df.columns:\n",
    "            hs_desc_col = cand\n",
    "            break\n",
    "\n",
    "    keep_cols = [month_col, hs_col, partner_col, exports_col] + ([hs_desc_col] if hs_desc_col else [])\n",
    "    df = df[keep_cols].copy()\n",
    "    df.columns = [\"Month\",\"HS\",\"Partner\",\"ExportsNZD\"] + ([\"hs_desc\"] if hs_desc_col else [])\n",
    "\n",
    "    # China only\n",
    "    df[\"Partner\"] = df[\"Partner\"].astype(str)\n",
    "    df = df[df[\"Partner\"].str.contains(\"china\", case=False, na=False)]\n",
    "\n",
    "    # HS → chapter → sector\n",
    "    df[\"HS_Chapter\"] = df[\"HS\"].apply(to_chapter)\n",
    "    df[\"Sector\"] = df[\"HS_Chapter\"].map(SECTOR_MAP)\n",
    "    if \"hs_desc\" in df.columns:\n",
    "        miss = df[\"Sector\"].isna()\n",
    "        if miss.any():\n",
    "            df.loc[miss, \"Sector\"] = df.loc[miss, \"hs_desc\"].apply(infer_sector_from_desc)\n",
    "\n",
    "    df = df[df[\"Sector\"].isin(KEEP_SECTORS)].copy()\n",
    "\n",
    "    # Numeric\n",
    "    if df[\"ExportsNZD\"].dtype == object:\n",
    "        df[\"ExportsNZD\"] = df[\"ExportsNZD\"].astype(str).str.replace(\",\", \"\", regex=False)\n",
    "    df[\"ExportsNZD\"] = pd.to_numeric(df[\"ExportsNZD\"], errors=\"coerce\").fillna(0.0)\n",
    "\n",
    "    # Month normalization & window\n",
    "    df[\"Month\"] = month_floor_to_str(df[\"Month\"])\n",
    "    parsed = pd.to_datetime(df[\"Month\"], format=\"%b-%Y\", errors=\"coerce\")\n",
    "    years = parsed.dt.year\n",
    "    df = df[years.between(2021, 2024, inclusive=\"both\")].copy()\n",
    "\n",
    "    print(\"[INFO] Chapters present:\", sorted(df[\"HS_Chapter\"].dropna().unique()))\n",
    "    print(\"[INFO] Sectors present:\", sorted(df[\"Sector\"].dropna().unique()))\n",
    "    return df\n",
    "\n",
    "def aggregate(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    agg = (df.groupby([\"Month\",\"HS_Chapter\",\"Sector\"], as_index=False)[\"ExportsNZD\"]\n",
    "             .sum()\n",
    "             .rename(columns={\"ExportsNZD\":\"Total_Exports_NZD\"}))\n",
    "    dt = pd.to_datetime(agg[\"Month\"], format=\"%b-%Y\", errors=\"coerce\")\n",
    "    agg = agg.assign(_dt=dt).sort_values([\"_dt\",\"HS_Chapter\"]).drop(columns=\"_dt\")\n",
    "    return agg[[\"Month\",\"HS_Chapter\",\"Sector\",\"Total_Exports_NZD\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01493da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5783896e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "824d806e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "def small_eda(wide_csv: Path, out_dir: Path):\n",
    "    print(\"\\n=== SMALL EDA ===\")\n",
    "    wide = pd.read_csv(wide_csv)\n",
    "    wide_dt = wide.copy()\n",
    "    wide_dt[\"Month_dt\"] = pd.to_datetime(wide_dt[\"Month\"], format=\"%b-%Y\", errors=\"coerce\")\n",
    "\n",
    "    # Descriptive stats\n",
    "    eda_stats = {}\n",
    "    for col in wide_dt.columns:\n",
    "        if col not in [\"Month\", \"Month_dt\"]:\n",
    "            eda_stats[col] = wide_dt[col].describe()\n",
    "    eda_df = pd.DataFrame(eda_stats).round(2)\n",
    "    print(\"[EDA] Sector descriptive stats:\")\n",
    "    if not eda_df.empty:\n",
    "        print(eda_df.to_string())\n",
    "\n",
    "    # Trend lines\n",
    "    plt.figure(figsize=(10,6))\n",
    "    for s in [\"Dairy\",\"Meat\",\"Fruit\",\"Forestry\"]:\n",
    "        if s in wide_dt.columns and wide_dt[s].notna().any():\n",
    "            plt.plot(wide_dt[\"Month_dt\"], wide_dt[s], label=s)\n",
    "    plt.title(\"NZ → China Exports by Sector (Monthly, 2021–2024)\")\n",
    "    plt.xlabel(\"Month\"); plt.ylabel(\"Exports NZD (FOB)\")\n",
    "    plt.xticks(rotation=45); plt.legend(); plt.tight_layout()\n",
    "    out_dir.mkdir(exist_ok=True)\n",
    "    plt.savefig(out_dir / \"eda_trends.png\", dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "    # Correlation\n",
    "    value_cols = [c for c in wide_dt.columns if c not in [\"Month\",\"Month_dt\"]]\n",
    "    if value_cols:\n",
    "        corr = wide_dt[value_cols].corr().values\n",
    "        plt.figure(figsize=(6,5))\n",
    "        plt.imshow(corr, aspect='auto')\n",
    "        plt.xticks(range(len(value_cols)), value_cols, rotation=45)\n",
    "        plt.yticks(range(len(value_cols)), value_cols)\n",
    "        plt.title(\"Sector Correlation (Pearson)\")\n",
    "        plt.colorbar(label=\"corr\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(out_dir / \"eda_correlation.png\", dpi=150)\n",
    "        plt.close()\n",
    "\n",
    "    # Missing values\n",
    "    na_counts = {c:int(wide_dt[c].isna().sum()) for c in value_cols}\n",
    "    print(\"[EDA] Missing values per sector:\", na_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "920bac12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ba6c747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecasting helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e78d0a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "def train_test_split_series(s: pd.Series, test_h=12):\n",
    "    train = s.iloc[:-test_h]\n",
    "    test  = s.iloc[-test_h:]\n",
    "    return train, test\n",
    "\n",
    "def metrics(y_true, y_pred):\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae  = mean_absolute_error(y_true, y_pred)\n",
    "    mape = (np.abs((y_true - y_pred) / np.clip(y_true, 1e-9, None))).mean() * 100\n",
    "    return rmse, mae, mape\n",
    "\n",
    "def make_lags(series: pd.Series, max_lag=12):\n",
    "    dfX = series.to_frame(\"y\")\n",
    "    for L in range(1, max_lag+1):\n",
    "        dfX[f\"lag_{L}\"] = dfX[\"y\"].shift(L)\n",
    "    return dfX.dropna()\n",
    "\n",
    "def residual_intervals(y_true_train, y_pred_train, y_pred_test, z=1.96):\n",
    "    resid = y_true_train - y_pred_train\n",
    "    sigma = np.std(resid)\n",
    "    lower = y_pred_test - z * sigma\n",
    "    upper = y_pred_test + z * sigma\n",
    "    return lower, upper\n",
    "\n",
    "def fit_arima(train, test, order=(2,1,2)):\n",
    "    m = ARIMA(train, order=order).fit()\n",
    "    fc = m.get_forecast(steps=len(test))\n",
    "    mean = pd.Series(fc.predicted_mean, index=test.index, name=\"ARIMA\")\n",
    "    conf = fc.conf_int(alpha=0.05)\n",
    "    lower = conf.iloc[:,0].set_axis(test.index)\n",
    "    upper = conf.iloc[:,1].set_axis(test.index)\n",
    "    return mean, lower, upper\n",
    "\n",
    "def fit_prophet(series, test_h=12):\n",
    "    if not HAVE_PROPHET:\n",
    "        return None\n",
    "    dfp = series.reset_index()\n",
    "    dfp.columns = [\"ds\",\"y\"]\n",
    "    train_p = dfp.iloc[:-test_h].copy()\n",
    "    test_p  = dfp.iloc[-test_h:].copy()\n",
    "    m = Prophet()\n",
    "    m.fit(train_p)\n",
    "    future = m.make_future_dataframe(periods=test_h, freq=\"MS\")\n",
    "    fcst = m.predict(future)\n",
    "    tail = fcst.iloc[-test_h:]\n",
    "    mean  = pd.Series(tail[\"yhat\"].values, index=test_p[\"ds\"], name=\"Prophet\")\n",
    "    lower = pd.Series(tail[\"yhat_lower\"].values, index=test_p[\"ds\"])\n",
    "    upper = pd.Series(tail[\"yhat_upper\"].values, index=test_p[\"ds\"])\n",
    "    return mean, lower, upper\n",
    "\n",
    "def fit_rf(series, test_h=12, max_lag=12, n_estimators=400, random_state=42, shap_summary=True):\n",
    "    dfX = make_lags(series, max_lag=max_lag)\n",
    "    X, y = dfX.drop(columns=[\"y\"]), dfX[\"y\"]\n",
    "    X_train, X_test = X.iloc[:-test_h], X.iloc[-test_h:]\n",
    "    y_train, y_test = y.iloc[:-test_h], y.iloc[-test_h:]\n",
    "    rf = RandomForestRegressor(n_estimators=n_estimators, random_state=random_state)\n",
    "    rf.fit(X_train, y_train)\n",
    "    pred_test = pd.Series(rf.predict(X_test), index=y_test.index, name=\"RandomForest\")\n",
    "    pred_train = rf.predict(X_train)\n",
    "    lower, upper = residual_intervals(y_train, pred_train, pred_test.values)\n",
    "    lower = pd.Series(lower, index=y_test.index)\n",
    "    upper = pd.Series(upper, index=y_test.index)\n",
    "    # Optional SHAP\n",
    "    if shap_summary and HAVE_SHAP:\n",
    "        try:\n",
    "            explainer = shap.TreeExplainer(rf)\n",
    "            shap_values = explainer.shap_values(X_train)\n",
    "            plt.figure()\n",
    "            shap.summary_plot(shap_values, X_train, show=False)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(OUT_DIR / \"shap_rf_summary.png\", dpi=140)\n",
    "            plt.close()\n",
    "        except Exception:\n",
    "            pass\n",
    "    return pred_test, lower, upper, rf\n",
    "\n",
    "def fit_xgb(series, test_h=12, max_lag=12, shap_summary=True):\n",
    "    if not HAVE_XGB:\n",
    "        return None\n",
    "    dfX = make_lags(series, max_lag=max_lag)\n",
    "    X, y = dfX.drop(columns=[\"y\"]), dfX[\"y\"]\n",
    "    X_train, X_test = X.iloc[:-test_h], X.iloc[-test_h:]\n",
    "    y_train, y_test = y.iloc[:-test_h], y.iloc[-test_h:]\n",
    "    xgb = XGBRegressor(\n",
    "        n_estimators=500, learning_rate=0.08, max_depth=4,\n",
    "        subsample=0.9, colsample_bytree=0.9, random_state=42\n",
    "    )\n",
    "    xgb.fit(X_train, y_train)\n",
    "    pred_test = pd.Series(xgb.predict(X_test), index=y_test.index, name=\"XGBoost\")\n",
    "    pred_train = xgb.predict(X_train)\n",
    "    lower, upper = residual_intervals(y_train, pred_train, pred_test.values)\n",
    "    lower = pd.Series(lower, index=y_test.index)\n",
    "    upper = pd.Series(upper, index=y_test.index)\n",
    "    if shap_summary and HAVE_SHAP:\n",
    "        try:\n",
    "            explainer = shap.TreeExplainer(xgb)\n",
    "            shap_values = explainer.shap_values(X_train)\n",
    "            plt.figure()\n",
    "            shap.summary_plot(shap_values, X_train, show=False)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(OUT_DIR / \"shap_xgb_summary.png\", dpi=140)\n",
    "            plt.close()\n",
    "        except Exception:\n",
    "            pass\n",
    "    return pred_test, lower, upper, xgb\n",
    "\n",
    "def fit_lstm(series, test_h=12, window=12, epochs=60, batch=8):\n",
    "    if not HAVE_TF:\n",
    "        return None\n",
    "    scaler = MinMaxScaler()\n",
    "    vals = series.values.reshape(-1,1)\n",
    "    scaled = scaler.fit_transform(vals)\n",
    "    X, y = [], []\n",
    "    for i in range(window, len(scaled)):\n",
    "        X.append(scaled[i-window:i])\n",
    "        y.append(scaled[i])\n",
    "    X, y = np.array(X), np.array(y)\n",
    "    X_train, X_test = X[:-test_h], X[-test_h:]\n",
    "    y_train, y_test = y[:-test_h], y[-test_h:]\n",
    "    model = Sequential([LSTM(64, activation=\"tanh\", input_shape=(window,1)), Dense(1)])\n",
    "    model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "    model.fit(X_train, y_train, epochs=60, batch_size=8, verbose=0)\n",
    "    pred_test_scaled = model.predict(X_test, verbose=0)\n",
    "    pred_train_scaled = model.predict(X_train, verbose=0)\n",
    "    pred_test = scaler.inverse_transform(pred_test_scaled).ravel()\n",
    "    pred_train = scaler.inverse_transform(pred_train_scaled).ravel()\n",
    "    y_train_inv = scaler.inverse_transform(y_train).ravel()\n",
    "    idx_test = series.index[-test_h:]\n",
    "    pred_series = pd.Series(pred_test, index=idx_test, name=\"LSTM\")\n",
    "    lower, upper = residual_intervals(y_train_inv, pred_train, pred_test)\n",
    "    lower = pd.Series(lower, index=idx_test)\n",
    "    upper = pd.Series(upper, index=idx_test)\n",
    "    return pred_series, lower, upper, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90e1fc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6bef41d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e26b634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loaded rows: 1299078 Columns: ['month', 'hs', 'hs_desc', 'uom', 'country', 'Export_FOB', 'Export_Qty', 'Re_export_FOB', 'Re_export_Qty', 'total_export_FOB', 'total_export_qty', 'status']\n",
      "[CHECK] Raw month samples: [202001, 202002, 202003, 202004, 202005, 202006, 202007, 202008, 202009, 202010, 202011, 202012, 202101, 202102, 202103]\n",
      "[INFO] Chapters present: ['10', '11', '12', '15', '16', '18', '19', '20', '21', '22', '23', '30', '32', '33', '35', '38', '40', '41', '42', '43', '44', '47', '48', '50', '51', '60', '64', '67', '68', '71', '73', '74', '80', '81', '82', '84', '85', '90', '94', '95', '96']\n",
      "[INFO] Sectors present: ['Dairy', 'Forestry', 'Fruit', 'Meat']\n",
      "\n",
      "[DIAG] Sector counts:\n",
      "Sector\n",
      "Meat        3471\n",
      "Dairy       1956\n",
      "Forestry    1293\n",
      "Fruit        896\n",
      "\n",
      "[DIAG] Totals by HS_Chapter (China only):\n",
      "HS_Chapter\n",
      "40    26238613228\n",
      "20    12699760488\n",
      "44    12669882690\n",
      "19     5146352680\n",
      "81     2879968208\n",
      "47     1078728842\n",
      "50      842681629\n",
      "80      842459804\n",
      "10      707827043\n",
      "35      457540700\n",
      "41      290868942\n",
      "23      252068137\n",
      "30      138453576\n",
      "84       47453263\n",
      "22       42671515\n",
      "15       17092883\n",
      "51        3648920\n",
      "21        1776750\n",
      "94        1529832\n",
      "43        1492092\n",
      "16        1251843\n",
      "32        1173668\n",
      "38         565810\n",
      "96         305570\n",
      "95         270315\n",
      "12         222028\n",
      "85          68840\n",
      "68          59095\n",
      "18          53140\n",
      "42          38831\n",
      "71          32853\n",
      "48          27337\n",
      "67          24386\n",
      "74          14928\n",
      "82           1468\n",
      "60           1322\n",
      "90             99\n",
      "11             65\n",
      "73             54\n",
      "33              0\n",
      "64              0\n",
      "[OK] wrote LONG: C:\\Users\\HP\\Documents\\MIT-final-project\\final-assignment\\omt_hs10_china_aggregated.csv\n",
      "[INFO] Found 192 Month–Sector combos across multiple HS chapters. Summing them.\n",
      "[OK] wrote WIDE: C:\\Users\\HP\\Documents\\MIT-final-project\\final-assignment\\omt_hs10_china_aggregated_wide.csv\n",
      "[CHECK] LONG month range: 2021-01-01 00:00:00 → 2024-12-01 00:00:00\n",
      "[CHECK] WIDE shape: (48, 5)\n",
      "[CHECK] WIDE columns: ['Month', 'Dairy', 'Forestry', 'Fruit', 'Meat']\n",
      "\n",
      "=== SMALL EDA ===\n",
      "[EDA] Sector descriptive stats:\n",
      "              Dairy      Forestry         Fruit          Meat\n",
      "count  4.800000e+01  4.800000e+01  4.800000e+01  4.800000e+01\n",
      "mean   6.770892e+08  2.864920e+08  7.928725e+07  2.980687e+08\n",
      "std    1.869744e+08  6.024762e+07  6.647540e+07  8.981627e+07\n",
      "min    3.282891e+08  1.504468e+08  3.048167e+06  9.804707e+07\n",
      "25%    5.586737e+08  2.440599e+08  1.360738e+07  2.392553e+08\n",
      "50%    6.726334e+08  2.817279e+08  6.995190e+07  3.010538e+08\n",
      "75%    7.492290e+08  3.299690e+08  1.167796e+08  3.710056e+08\n",
      "max    1.306456e+09  4.342396e+08  2.425547e+08  4.584791e+08\n",
      "[EDA] Missing values per sector: {'Dairy': 0, 'Forestry': 0, 'Fruit': 0, 'Meat': 0}\n",
      "\n",
      "=== Metrics (sorted by RMSE) ===\n",
      "  Sector   Model         RMSE          MAE       MAPE\n",
      "   Dairy      RF 1.757500e+08 1.383462e+08  24.258563\n",
      "   Dairy   ARIMA 1.900835e+08 1.407352e+08  24.715279\n",
      "   Dairy Prophet          NaN          NaN        NaN\n",
      "   Dairy     XGB          NaN          NaN        NaN\n",
      "   Dairy    LSTM          NaN          NaN        NaN\n",
      "Forestry   ARIMA 5.153307e+07 4.246730e+07  17.119845\n",
      "Forestry      RF 5.509155e+07 4.442826e+07  18.348211\n",
      "Forestry Prophet          NaN          NaN        NaN\n",
      "Forestry     XGB          NaN          NaN        NaN\n",
      "Forestry    LSTM          NaN          NaN        NaN\n",
      "   Fruit      RF 4.466190e+07 3.585364e+07  69.709519\n",
      "   Fruit   ARIMA 6.344894e+07 5.245781e+07 171.720416\n",
      "   Fruit Prophet          NaN          NaN        NaN\n",
      "   Fruit     XGB          NaN          NaN        NaN\n",
      "   Fruit    LSTM          NaN          NaN        NaN\n",
      "    Meat      RF 7.454368e+07 6.126817e+07  41.731135\n",
      "    Meat   ARIMA 1.116279e+08 9.133771e+07  64.504318\n",
      "    Meat Prophet          NaN          NaN        NaN\n",
      "    Meat     XGB          NaN          NaN        NaN\n",
      "    Meat    LSTM          NaN          NaN        NaN\n",
      "\n",
      "=== Per-sector winners ===\n",
      "  Sector Model         RMSE          MAE      MAPE\n",
      "   Dairy    RF 1.757500e+08 1.383462e+08 24.258563\n",
      "Forestry ARIMA 5.153307e+07 4.246730e+07 17.119845\n",
      "   Fruit    RF 4.466190e+07 3.585364e+07 69.709519\n",
      "    Meat    RF 7.454368e+07 6.126817e+07 41.731135\n",
      "- Dairy: RF lowest RMSE (175,750,029), MAE 138,346,185, MAPE 24.26%.\n",
      "- Forestry: ARIMA lowest RMSE (51,533,074), MAE 42,467,304, MAPE 17.12%.\n",
      "- Fruit: RF lowest RMSE (44,661,898), MAE 35,853,635, MAPE 69.71%.\n",
      "- Meat: RF lowest RMSE (74,543,683), MAE 61,268,171, MAPE 41.73%.\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "def main():\n",
    "    # Load & normalize\n",
    "    raw = load_and_stack(IN_DIR)\n",
    "\n",
    "    try:\n",
    "        raw_month_col = detect_col(raw, [\"Month\",\"month\",\"Date\",\"Period\"], \"Month\")\n",
    "        print(\"[CHECK] Raw month samples:\", raw[raw_month_col].drop_duplicates().head(15).tolist())\n",
    "    except Exception as e:\n",
    "        print(\"[CHECK] Could not sample raw months:\", e)\n",
    "\n",
    "    norm = normalize_and_filter(raw, PREFER_TOTAL_EXPORTS)\n",
    "\n",
    "    print(\"\\n[DIAG] Sector counts:\")\n",
    "    print(norm[\"Sector\"].value_counts(dropna=False).to_string())\n",
    "\n",
    "    print(\"\\n[DIAG] Totals by HS_Chapter (China only):\")\n",
    "    print(norm.groupby(\"HS_Chapter\")[\"ExportsNZD\"].sum().sort_values(ascending=False).to_string())\n",
    "\n",
    "    # Aggregate (Month–HS_Chapter–Sector)\n",
    "    out = aggregate(norm)\n",
    "\n",
    "    # Write LONG file\n",
    "    out.to_csv(OUT_FILE_LONG, index=False)\n",
    "    print(f\"[OK] wrote LONG: {OUT_FILE_LONG.resolve()}\")\n",
    "\n",
    "    # FIX: collapse to Month–Sector totals BEFORE pivot (avoid duplicate Month–Sector)\n",
    "    dup_diag = out.groupby([\"Month\",\"Sector\"]).size().reset_index(name=\"rows_per_pair\")\n",
    "    multi = dup_diag[dup_diag[\"rows_per_pair\"] > 1]\n",
    "    if not multi.empty:\n",
    "        print(f\"[INFO] Found {len(multi)} Month–Sector combos across multiple HS chapters. Summing them.\")\n",
    "\n",
    "    out_ms = out.groupby([\"Month\",\"Sector\"], as_index=False)[\"Total_Exports_NZD\"].sum()\n",
    "\n",
    "    # Safe pivot (Month × Sector)\n",
    "    wide = out_ms.pivot(index=\"Month\", columns=\"Sector\", values=\"Total_Exports_NZD\").reset_index()\n",
    "\n",
    "    # Write WIDE file\n",
    "    wide.to_csv(OUT_FILE_WIDE, index=False)\n",
    "    print(f\"[OK] wrote WIDE: {OUT_FILE_WIDE.resolve()}\")\n",
    "\n",
    "    # Diagnostics\n",
    "    dt_out = pd.to_datetime(out[\"Month\"], format=\"%b-%Y\", errors=\"coerce\")\n",
    "    print(\"[CHECK] LONG month range:\", dt_out.min(), \"→\", dt_out.max())\n",
    "    print(\"[CHECK] WIDE shape:\", wide.shape)\n",
    "    print(\"[CHECK] WIDE columns:\", list(wide.columns))\n",
    "\n",
    "    # EDA\n",
    "    small_eda(OUT_FILE_WIDE, OUT_DIR)\n",
    "\n",
    "    # Forecasting\n",
    "    forecast_all()\n",
    "\n",
    "def forecast_all(test_h: int = 12):\n",
    "    # Rebuild wide safely from LONG\n",
    "    df_long = pd.read_csv(OUT_FILE_LONG)\n",
    "    df_ms = df_long.groupby([\"Month\",\"Sector\"], as_index=False)[\"Total_Exports_NZD\"].sum()\n",
    "    wide = df_ms.pivot(index=\"Month\", columns=\"Sector\", values=\"Total_Exports_NZD\").sort_index()\n",
    "\n",
    "    # Make datetime index\n",
    "    wide_dt = wide.copy()\n",
    "    wide_dt.index = pd.to_datetime(wide_dt.index, format=\"%b-%Y\", errors=\"coerce\")\n",
    "    wide_dt = wide_dt.sort_index()\n",
    "\n",
    "    sectors_all = [\"Dairy\",\"Meat\",\"Fruit\",\"Forestry\"]\n",
    "    present = [s for s in sectors_all if s in wide_dt.columns and wide_dt[s].notna().any()]\n",
    "    if not present:\n",
    "        raise RuntimeError(\n",
    "            \"No target sectors (Dairy/Meat/Fruit/Forestry) found after filtering.\\n\"\n",
    "            f\"Available columns: {list(wide_dt.columns)}\"\n",
    "        )\n",
    "    missing = [s for s in sectors_all if s not in present]\n",
    "    if missing:\n",
    "        print(f\"[WARN] Missing sectors: {missing}. Proceeding with: {present}\")\n",
    "\n",
    "    rows = []\n",
    "    for sector in present:\n",
    "        s = wide_dt[sector].asfreq(\"MS\").fillna(0.0)\n",
    "        train, test = train_test_split_series(s, test_h=test_h)\n",
    "\n",
    "        # ARIMA\n",
    "        arima_pred, arima_lo, arima_hi = fit_arima(train, test, order=(2,1,2))\n",
    "        arima_rmse, arima_mae, arima_mape = metrics(test.values, arima_pred.values)\n",
    "\n",
    "        # Prophet (optional)\n",
    "        if HAVE_PROPHET:\n",
    "            pr = fit_prophet(s, test_h=test_h)\n",
    "            if pr is not None:\n",
    "                prophet_pred, prophet_lo, prophet_hi = pr\n",
    "                prophet_rmse, prophet_mae, prophet_mape = metrics(test.values, prophet_pred.values)\n",
    "            else:\n",
    "                prophet_pred = prophet_lo = prophet_hi = None\n",
    "                prophet_rmse = prophet_mae = prophet_mape = np.nan\n",
    "        else:\n",
    "            prophet_pred = prophet_lo = prophet_hi = None\n",
    "            prophet_rmse = prophet_mae = prophet_mape = np.nan\n",
    "\n",
    "        # Random Forest (+ SHAP)\n",
    "        rf_pred, rf_lo, rf_hi, _rf = fit_rf(s, test_h=test_h, shap_summary=True)\n",
    "        rf_rmse, rf_mae, rf_mape = metrics(test.values, rf_pred.values)\n",
    "\n",
    "        # XGBoost (optional)\n",
    "        if HAVE_XGB:\n",
    "            xgbo = fit_xgb(s, test_h=test_h, shap_summary=True)\n",
    "            if xgbo is not None:\n",
    "                xgb_pred, xgb_lo, xgb_hi, _xgb = xgbo\n",
    "                xgb_rmse, xgb_mae, xgb_mape = metrics(test.values, xgb_pred.values)\n",
    "            else:\n",
    "                xgb_pred = xgb_lo = xgb_hi = None\n",
    "                xgb_rmse = xgb_mae = xgb_mape = np.nan\n",
    "        else:\n",
    "            xgb_pred = xgb_lo = xgb_hi = None\n",
    "            xgb_rmse = xgb_mae = xgb_mape = np.nan\n",
    "\n",
    "        # LSTM (optional)\n",
    "        if HAVE_TF:\n",
    "            lstmo = fit_lstm(s, test_h=test_h, window=12, epochs=60, batch=8)\n",
    "            if lstmo is not None:\n",
    "                lstm_pred, lstm_lo, lstm_hi, _lstm = lstmo\n",
    "                lstm_rmse, lstm_mae, lstm_mape = metrics(test.values, lstm_pred.values)\n",
    "            else:\n",
    "                lstm_pred = lstm_lo = lstm_hi = None\n",
    "                lstm_rmse = lstm_mae = lstm_mape = np.nan\n",
    "        else:\n",
    "            lstm_pred = lstm_lo = lstm_hi = None\n",
    "            lstm_rmse = lstm_mae = lstm_mape = np.nan\n",
    "\n",
    "        rows += [\n",
    "            {\"Sector\": sector, \"Model\":\"ARIMA\",   \"RMSE\":arima_rmse,  \"MAE\":arima_mae,  \"MAPE\":arima_mape},\n",
    "            {\"Sector\": sector, \"Model\":\"Prophet\", \"RMSE\":prophet_rmse,\"MAE\":prophet_mae,\"MAPE\":prophet_mape},\n",
    "            {\"Sector\": sector, \"Model\":\"RF\",      \"RMSE\":rf_rmse,     \"MAE\":rf_mae,     \"MAPE\":rf_mape},\n",
    "            {\"Sector\": sector, \"Model\":\"XGB\",     \"RMSE\":xgb_rmse,    \"MAE\":xgb_mae,    \"MAPE\":xgb_mape},\n",
    "            {\"Sector\": sector, \"Model\":\"LSTM\",    \"RMSE\":lstm_rmse,   \"MAE\":lstm_mae,   \"MAPE\":lstm_mape},\n",
    "        ]\n",
    "\n",
    "        # Save forecasts per sector\n",
    "        out_df = pd.DataFrame({\"Actual\": test})\n",
    "        out_df[\"ARIMA\"] = arima_pred\n",
    "        out_df[\"ARIMA_lo95\"] = arima_lo\n",
    "        out_df[\"ARIMA_hi95\"] = arima_hi\n",
    "        if \"prophet_pred\" in locals() and prophet_pred is not None:\n",
    "            out_df[\"Prophet\"] = prophet_pred.reindex(out_df.index)\n",
    "            out_df[\"Prophet_lo95\"] = prophet_lo.reindex(out_df.index)\n",
    "            out_df[\"Prophet_hi95\"] = prophet_hi.reindex(out_df.index)\n",
    "        out_df[\"RF\"] = rf_pred\n",
    "        out_df[\"RF_lo95\"] = rf_lo\n",
    "        out_df[\"RF_hi95\"] = rf_hi\n",
    "        if \"xgb_pred\" in locals() and xgb_pred is not None:\n",
    "            out_df[\"XGB\"] = xgb_pred\n",
    "            out_df[\"XGB_lo95\"] = xgb_lo\n",
    "            out_df[\"XGB_hi95\"] = xgb_hi\n",
    "        if \"lstm_pred\" in locals() and lstm_pred is not None:\n",
    "            out_df[\"LSTM\"] = lstm_pred\n",
    "            out_df[\"LSTM_lo95\"] = lstm_lo\n",
    "            out_df[\"LSTM_hi95\"] = lstm_hi\n",
    "\n",
    "        OUT_DIR.mkdir(exist_ok=True)\n",
    "        out_df.to_csv(OUT_DIR / f\"forecasts_{sector}.csv\")\n",
    "\n",
    "        # Plot\n",
    "        plt.figure(figsize=(10,6))\n",
    "        plt.plot(out_df.index, out_df[\"Actual\"].values, label=\"Actual\", linewidth=2)\n",
    "        plt.plot(out_df.index, out_df[\"ARIMA\"].values, label=\"ARIMA\")\n",
    "        if \"Prophet\" in out_df.columns:\n",
    "            plt.plot(out_df.index, out_df[\"Prophet\"].values, label=\"Prophet\", alpha=0.9)\n",
    "        plt.plot(out_df.index, out_df[\"RF\"].values, label=\"RF\", alpha=0.9)\n",
    "        if \"XGB\" in out_df.columns:\n",
    "            plt.plot(out_df.index, out_df[\"XGB\"].values, label=\"XGB\", alpha=0.9)\n",
    "        if \"LSTM\" in out_df.columns:\n",
    "            plt.plot(out_df.index, out_df[\"LSTM\"].values, label=\"LSTM\", alpha=0.9)\n",
    "        plt.title(f\"{sector}: Last 12 Months — Actual vs Forecasts\")\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(OUT_DIR / f\"plot_{sector}.png\", dpi=150)\n",
    "        plt.close()\n",
    "\n",
    "    # Metrics table and winners\n",
    "    metrics_df = pd.DataFrame(rows)\n",
    "    if metrics_df.empty:\n",
    "        raise RuntimeError(\n",
    "            \"No metrics were produced (rows is empty). \"\n",
    "            \"Likely no sectors had usable data after filters.\\n\"\n",
    "            \"Check 'omt_hs10_china_aggregated_wide.csv'.\"\n",
    "        )\n",
    "    metrics_df = metrics_df.sort_values([\"Sector\",\"RMSE\"])\n",
    "    OUT_DIR.mkdir(exist_ok=True)\n",
    "    metrics_df.to_csv(OUT_DIR / \"model_results.csv\", index=False)\n",
    "    print(\"\\n=== Metrics (sorted by RMSE) ===\")\n",
    "    print(metrics_df.to_string(index=False))\n",
    "\n",
    "    winners = metrics_df.loc[metrics_df.groupby(\"Sector\")[\"RMSE\"].idxmin()].reset_index(drop=True)\n",
    "    print(\"\\n=== Per-sector winners ===\")\n",
    "    print(winners.to_string(index=False))\n",
    "\n",
    "    for _, row in winners.iterrows():\n",
    "        s, model, rmse, mae, mape = row[\"Sector\"], row[\"Model\"], row[\"RMSE\"], row[\"MAE\"], row[\"MAPE\"]\n",
    "        print(f\"- {s}: {model} lowest RMSE ({rmse:,.0f}), MAE {mae:,.0f}, MAPE {mape:.2f}%.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
